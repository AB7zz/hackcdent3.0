{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55aac436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from geopy) (2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c04c33b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df698bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twilio in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (8.9.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from twilio) (2022.5)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from twilio) (2.28.1)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from twilio) (2.8.0)\n",
      "Requirement already satisfied: aiohttp>=3.8.4 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from twilio) (3.8.4)\n",
      "Requirement already satisfied: aiohttp-retry>=2.8.3 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from twilio) (2.8.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.0.0->twilio) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.0.0->twilio) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thepywizard\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.0.0->twilio) (2022.9.24)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install twilio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93c20982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2     # for capturing videos\n",
    "import math \n",
    "import geocoder\n",
    "import requests\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from twilio.rest import Client\n",
    "from geopy.geocoders import Nominatim\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt \n",
    "from skimage.transform import resize   # for resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d50c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"Accidents.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)   # capturing the video from the given path\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "path = \"./traindata/\"\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =path+\"%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed1ec509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f52dc23fa0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAFHCAYAAACLR7eXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAeS0lEQVR4nO3df2yV9fn/8VdL20NrOS1Q2lKlgMpE5McUtDu6xWQ0VNY4FbKg6ZYqTgOWDZAwqQaY21zJTLbp5nCbG5joZHYRJgzQrsUyZy1QqZYfqzjRNsBpVdJzCkJ/Xp8//HJ/PcKU8qvvc3w+kiuh9/s657wvbjzn5em52zgzMwEAADgkvr83AAAA8FkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgnH4NKE888YRGjRqlgQMHKi8vT9u2bevP7QAAAEf0W0D561//qvvvv1/Lly/XG2+8oUmTJqmgoECtra39tSUAAOCIuP76ZYF5eXm69tpr9dvf/laS1NvbqxEjRugHP/iBlixZ8rm37e3t1cGDBzVo0CDFxcVdiO0CAICzZGZqb29XTk6O4uM//z2ShAu0pwidnZ2qq6tTaWmpdyw+Pl75+fmqqak5qb+jo0MdHR3e1wcOHNC4ceMuyF4BAMC51dzcrEsuueRze/rlWzwffvihenp6lJWVFXE8KytLwWDwpP6ysjKlpaV5RTgBACB6DRo06At7ouIqntLSUoVCIa+am5v7e0sAAOAMnc7HM/rlWzwZGRkaMGCAWlpaIo63tLQoOzv7pH6fzyefz3ehtgcAAPpZv7yDkpSUpMmTJ6uystI71tvbq8rKSgUCgf7YEgAAcEi/vIMiSffff7+Ki4s1ZcoUXXfddfr1r3+to0eP6q677uqvLQEAAEf0W0CZNWuWPvjgAy1btkzBYFBf/epXtXnz5pM+OAsAAL58+u3noJyNcDistLS0/t4GAAA4A6FQSH6//3N7ouIqHgAA8OVCQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHBOnwPK1q1bdfPNNysnJ0dxcXFat25dxLqZadmyZRo+fLiSk5OVn5+vffv2RfQcPnxYRUVF8vv9Sk9P1913360jR46c1SAAACB29DmgHD16VJMmTdITTzxxyvVf/OIXevzxx/Xkk0+qtrZWF110kQoKCnT8+HGvp6ioSLt371ZFRYU2bNigrVu36t577z3zKQAAQGyxsyDJ1q5d633d29tr2dnZ9uijj3rH2trazOfz2XPPPWdmZnv27DFJtn37dq9n06ZNFhcXZwcOHDitxw2FQiaJoiiKoqgorFAo9IWv9ef0Myj79+9XMBhUfn6+dywtLU15eXmqqamRJNXU1Cg9PV1TpkzxevLz8xUfH6/a2tpT3m9HR4fC4XBEAQCA2HVOA0owGJQkZWVlRRzPysry1oLBoDIzMyPWExISNGTIEK/ns8rKypSWlubViBEjzuW2AQCAY6LiKp7S0lKFQiGvmpub+3tLAADgPDqnASU7O1uS1NLSEnG8paXFW8vOzlZra2vEend3tw4fPuz1fJbP55Pf748oAAAQu85pQBk9erSys7NVWVnpHQuHw6qtrVUgEJAkBQIBtbW1qa6uzuupqqpSb2+v8vLyzuV2AABAlEro6w2OHDmid955x/t6//79qq+v15AhQ5Sbm6sFCxboZz/7mcaMGaPRo0dr6dKlysnJ0a233ipJuvLKK3XTTTfpnnvu0ZNPPqmuri7NmzdPt99+u3Jycs7ZYAAAIIqd5hXFni1btpzykqHi4mIz++RS46VLl1pWVpb5fD6bOnWqNTY2RtzHRx99ZHfccYelpqaa3++3u+66y9rb2097D1xmTFEURVHRW6dzmXGcmZmiTDgcVlpaWn9vAwAAnIFQKPSFnyeNiqt4AADAlwsBBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDl9CihlZWW69tprNWjQIGVmZurWW29VY2NjRM/x48dVUlKioUOHKjU1VTNnzlRLS0tET1NTkwoLC5WSkqLMzEwtXrxY3d3dZz8NAACICX0KKNXV1SopKdHrr7+uiooKdXV1adq0aTp69KjXs3DhQq1fv17l5eWqrq7WwYMHNWPGDG+9p6dHhYWF6uzs1Guvvaann35aq1ev1rJly87dVAAAILrZWWhtbTVJVl1dbWZmbW1tlpiYaOXl5V7P3r17TZLV1NSYmdnGjRstPj7egsGg17Ny5Urz+/3W0dFxWo8bCoVMEkVRFEVRUVihUOgLX+vP6jMooVBIkjRkyBBJUl1dnbq6upSfn+/1jB07Vrm5uaqpqZEk1dTUaMKECcrKyvJ6CgoKFA6HtXv37lM+TkdHh8LhcEQBAIDYdcYBpbe3VwsWLNANN9yg8ePHS5KCwaCSkpKUnp4e0ZuVlaVgMOj1fDqcnFg/sXYqZWVlSktL82rEiBFnum0AABAFzjiglJSUaNeuXVqzZs253M8plZaWKhQKedXc3HzeHxMAAPSfhDO50bx587RhwwZt3bpVl1xyiXc8OztbnZ2damtri3gXpaWlRdnZ2V7Ptm3bIu7vxFU+J3o+y+fzyefznclWAQBAFOrTOyhmpnnz5mnt2rWqqqrS6NGjI9YnT56sxMREVVZWescaGxvV1NSkQCAgSQoEAmpoaFBra6vXU1FRIb/fr3Hjxp3NLAAAIFb04aIdmzt3rqWlpdkrr7xihw4d8urjjz/2eubMmWO5ublWVVVlO3bssEAgYIFAwFvv7u628ePH27Rp06y+vt42b95sw4YNs9LS0tPeB1fxUBRFUVT01ulcxdOngPK/HmjVqlVez7Fjx+y+++6zwYMHW0pKit1222126NChiPt57733bPr06ZacnGwZGRm2aNEi6+rqOu19EFAoiqIoKnrrdAJK3P8LHlElHA4rLS2tv7cBAADOQCgUkt/v/9wefhcPAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOX0KKCtXrtTEiRPl9/vl9/sVCAS0adMmb/348eMqKSnR0KFDlZqaqpkzZ6qlpSXiPpqamlRYWKiUlBRlZmZq8eLF6u7uPjfTAACAmNCngHLJJZdoxYoVqqur044dO/TNb35Tt9xyi3bv3i1JWrhwodavX6/y8nJVV1fr4MGDmjFjhnf7np4eFRYWqrOzU6+99pqefvpprV69WsuWLTu3UwEAgOhmZ2nw4MH21FNPWVtbmyUmJlp5ebm3tnfvXpNkNTU1Zma2ceNGi4+Pt2Aw6PWsXLnS/H6/dXR0nPZjhkIhk0RRFEVRVBRWKBT6wtf6M/4MSk9Pj9asWaOjR48qEAiorq5OXV1dys/P93rGjh2r3Nxc1dTUSJJqamo0YcIEZWVleT0FBQUKh8PeuzCn0tHRoXA4HFEAACB29TmgNDQ0KDU1VT6fT3PmzNHatWs1btw4BYNBJSUlKT09PaI/KytLwWBQkhQMBiPCyYn1E2v/S1lZmdLS0rwaMWJEX7cNAACiSJ8DyhVXXKH6+nrV1tZq7ty5Ki4u1p49e87H3jylpaUKhUJeNTc3n9fHAwAA/SuhrzdISkrS5ZdfLkmaPHmytm/frscee0yzZs1SZ2en2traIt5FaWlpUXZ2tiQpOztb27Zti7i/E1f5nOg5FZ/PJ5/P19etAgCAKHXWPwelt7dXHR0dmjx5shITE1VZWemtNTY2qqmpSYFAQJIUCATU0NCg1tZWr6eiokJ+v1/jxo07260AAIBY0YcLdmzJkiVWXV1t+/fvt7feesuWLFlicXFx9vLLL5uZ2Zw5cyw3N9eqqqpsx44dFggELBAIeLfv7u628ePH27Rp06y+vt42b95sw4YNs9LS0r5sg6t4KIqiKCqK63Su4ulTQJk9e7aNHDnSkpKSbNiwYTZ16lQvnJiZHTt2zO677z4bPHiwpaSk2G233WaHDh2KuI/33nvPpk+fbsnJyZaRkWGLFi2yrq6uvmyDgEJRFEVRUVynE1DizMwUZcLhsNLS0vp7GwAA4AyEQiH5/f7P7eF38QAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxzVgFlxYoViouL04IFC7xjx48fV0lJiYYOHarU1FTNnDlTLS0tEbdrampSYWGhUlJSlJmZqcWLF6u7u/tstgIAAGLIGQeU7du36/e//70mTpwYcXzhwoVav369ysvLVV1drYMHD2rGjBneek9PjwoLC9XZ2anXXntNTz/9tFavXq1ly5ad+RQAACC22Blob2+3MWPGWEVFhd144402f/58MzNra2uzxMREKy8v93r37t1rkqympsbMzDZu3Gjx8fEWDAa9npUrV5rf77eOjo7TevxQKGSSKIqiKIqKwgqFQl/4Wn9G76CUlJSosLBQ+fn5Ecfr6urU1dUVcXzs2LHKzc1VTU2NJKmmpkYTJkxQVlaW11NQUKBwOKzdu3ef8vE6OjoUDocjCgAAxK6Evt5gzZo1euONN7R9+/aT1oLBoJKSkpSenh5xPCsrS8Fg0Ov5dDg5sX5i7VTKysr08MMP93WrAAAgSvXpHZTm5mbNnz9fzz77rAYOHHi+9nSS0tJShUIhr5qbmy/YYwMAgAuvTwGlrq5Ora2tuuaaa5SQkKCEhARVV1fr8ccfV0JCgrKystTZ2am2traI27W0tCg7O1uSlJ2dfdJVPSe+PtHzWT6fT36/P6IAAEDs6lNAmTp1qhoaGlRfX+/VlClTVFRU5P05MTFRlZWV3m0aGxvV1NSkQCAgSQoEAmpoaFBra6vXU1FRIb/fr3Hjxp2jsQAAQFTrw8U7p/Tpq3jMzObMmWO5ublWVVVlO3bssEAgYIFAwFvv7u628ePH27Rp06y+vt42b95sw4YNs9LS0tN+TK7ioSiKoqjordO5iqfPH5L9Ir/61a8UHx+vmTNnqqOjQwUFBfrd737nrQ8YMEAbNmzQ3LlzFQgEdNFFF6m4uFg/+clPzvVWAABAlIozM+vvTfRVOBxWWlpaf28DAACcgVAo9IWfJ+V38QAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4h4ACAACcQ0ABAADOIaAAAADnEFAAAIBzCCgAAMA5BBQAAOAcAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOIeAAgAAnENAAQAAziGgAAAA5xBQAACAcwgoAADAOQQUAADgHAIKAABwDgEFAAA4JyoDipn19xYAAMAZOp3X8agMKB999FF/bwEAAJyh9vb2L+xJuAD7OOeGDBkiSWpqalJaWlo/7+b8CYfDGjFihJqbm+X3+/t7O+fVl2VW5owtzBlbmPP8MzO1t7crJyfnC3ujMqDEx3/yxk9aWlpM/yM6we/3fynmlL48szJnbGHO2MKc59fpvrEQld/iAQAAsY2AAgAAnBOVAcXn82n58uXy+Xz9vZXz6ssyp/TlmZU5YwtzxhbmdEuccc0uAABwTFS+gwIAAGIbAQUAADiHgAIAAJxDQAEAAM4hoAAAAOdEZUB54oknNGrUKA0cOFB5eXnatm1bf2+pT7Zu3aqbb75ZOTk5iouL07p16yLWzUzLli3T8OHDlZycrPz8fO3bty+i5/DhwyoqKpLf71d6erruvvtuHTly5AJO8fnKysp07bXXatCgQcrMzNStt96qxsbGiJ7jx4+rpKREQ4cOVWpqqmbOnKmWlpaInqamJhUWFiolJUWZmZlavHixuru7L+QoX2jlypWaOHGi91MZA4GANm3a5K3HypyftmLFCsXFxWnBggXesViZ88c//rHi4uIiauzYsd56rMwpSQcOHNB3v/tdDR06VMnJyZowYYJ27NjhrcfCc9GoUaNOOp9xcXEqKSmRFDvns6enR0uXLtXo0aOVnJysyy67TD/96U8jfilf1J1PizJr1qyxpKQk+/Of/2y7d++2e+65x9LT062lpaW/t3baNm7caA899JC98MILJsnWrl0bsb5ixQpLS0uzdevW2Ztvvmnf/va3bfTo0Xbs2DGv56abbrJJkybZ66+/bv/617/s8ssvtzvuuOMCT/K/FRQU2KpVq2zXrl1WX19v3/rWtyw3N9eOHDni9cyZM8dGjBhhlZWVtmPHDvva175m119/vbfe3d1t48ePt/z8fNu5c6dt3LjRMjIyrLS0tD9G+p9efPFF+8c//mFvv/22NTY22oMPPmiJiYm2a9cuM4udOU/Ytm2bjRo1yiZOnGjz58/3jsfKnMuXL7errrrKDh065NUHH3zgrcfKnIcPH7aRI0fanXfeabW1tfbuu+/aSy+9ZO+8847XEwvPRa2trRHnsqKiwiTZli1bzCx2zucjjzxiQ4cOtQ0bNtj+/futvLzcUlNT7bHHHvN6ou18Rl1Aue6666ykpMT7uqenx3JycqysrKwfd3XmPhtQent7LTs72x599FHvWFtbm/l8PnvuuefMzGzPnj0mybZv3+71bNq0yeLi4uzAgQMXbO990draapKsurrazD6ZKTEx0crLy72evXv3miSrqakxs0+CXHx8vAWDQa9n5cqV5vf7raOj48IO0EeDBw+2p556KubmbG9vtzFjxlhFRYXdeOONXkCJpTmXL19ukyZNOuVaLM35wAMP2Ne//vX/uR6rz0Xz58+3yy67zHp7e2PqfBYWFtrs2bMjjs2YMcOKiorMLDrPZ1R9i6ezs1N1dXXKz8/3jsXHxys/P181NTX9uLNzZ//+/QoGgxEzpqWlKS8vz5uxpqZG6enpmjJliteTn5+v+Ph41dbWXvA9n45QKCTp//8m6rq6OnV1dUXMOXbsWOXm5kbMOWHCBGVlZXk9BQUFCofD2r179wXc/enr6enRmjVrdPToUQUCgZibs6SkRIWFhRHzSLF3Pvft26ecnBxdeumlKioqUlNTk6TYmvPFF1/UlClT9J3vfEeZmZm6+uqr9cc//tFbj8Xnos7OTj3zzDOaPXu24uLiYup8Xn/99aqsrNTbb78tSXrzzTf16quvavr06ZKi83xG1W8z/vDDD9XT0xPxD0WSsrKy9J///KefdnVuBYNBSTrljCfWgsGgMjMzI9YTEhI0ZMgQr8clvb29WrBggW644QaNHz9e0iczJCUlKT09PaL3s3Oe6u/hxJpLGhoaFAgEdPz4caWmpmrt2rUaN26c6uvrY2bONWvW6I033tD27dtPWoul85mXl6fVq1friiuu0KFDh/Twww/rG9/4hnbt2hVTc7777rtauXKl7r//fj344IPavn27fvjDHyopKUnFxcUx+Vy0bt06tbW16c4775QUW/9ulyxZonA4rLFjx2rAgAHq6enRI488oqKiIknR+doSVQEF0amkpES7du3Sq6++2t9bOW+uuOIK1dfXKxQK6W9/+5uKi4tVXV3d39s6Z5qbmzV//nxVVFRo4MCB/b2d8+rE/3FK0sSJE5WXl6eRI0fq+eefV3Jycj/u7Nzq7e3VlClT9POf/1ySdPXVV2vXrl168sknVVxc3M+7Oz/+9Kc/afr06crJyenvrZxzzz//vJ599ln95S9/0VVXXaX6+notWLBAOTk5UXs+o+pbPBkZGRowYMBJn7BuaWlRdnZ2P+3q3Doxx+fNmJ2drdbW1oj17u5uHT582Lm/h3nz5mnDhg3asmWLLrnkEu94dna2Ojs71dbWFtH/2TlP9fdwYs0lSUlJuvzyyzV58mSVlZVp0qRJeuyxx2Jmzrq6OrW2tuqaa65RQkKCEhISVF1drccff1wJCQnKysqKiTlPJT09XV/5ylf0zjvvxMz5lKThw4dr3LhxEceuvPJK79tZsfZc9P777+uf//ynvv/973vHYul8Ll68WEuWLNHtt9+uCRMm6Hvf+54WLlyosrIySdF5PqMqoCQlJWny5MmqrKz0jvX29qqyslKBQKAfd3bujB49WtnZ2REzhsNh1dbWejMGAgG1tbWprq7O66mqqlJvb6/y8vIu+J5Pxcw0b948rV27VlVVVRo9enTE+uTJk5WYmBgxZ2Njo5qamiLmbGhoiPgPpqKiQn6//6QnVtf09vaqo6MjZuacOnWqGhoaVF9f79WUKVNUVFTk/TkW5jyVI0eO6L///a+GDx8eM+dTkm644YaTLv1/++23NXLkSEmx81x0wqpVq5SZmanCwkLvWCydz48//ljx8ZEv6QMGDFBvb6+kKD2fF/xjuWdpzZo15vP5bPXq1bZnzx679957LT09PeIT1q5rb2+3nTt32s6dO02S/fKXv7SdO3fa+++/b2afXAqWnp5uf//73+2tt96yW2655ZSXgl199dVWW1trr776qo0ZM8apS/vmzp1raWlp9sorr0Rc4vfxxx97PXPmzLHc3FyrqqqyHTt2WCAQsEAg4K2fuLxv2rRpVl9fb5s3b7Zhw4Y5d3nfkiVLrLq62vbv329vvfWWLVmyxOLi4uzll182s9iZ87M+fRWPWezMuWjRInvllVds//799u9//9vy8/MtIyPDWltbzSx25ty2bZslJCTYI488Yvv27bNnn33WUlJS7JlnnvF6YuG5yOyTqz1zc3PtgQceOGktVs5ncXGxXXzxxd5lxi+88IJlZGTYj370I68n2s5n1AUUM7Pf/OY3lpuba0lJSXbdddfZ66+/3t9b6pMtW7aYpJOquLjYzD65HGzp0qWWlZVlPp/Ppk6dao2NjRH38dFHH9kdd9xhqamp5vf77a677rL29vZ+mObUTjWfJFu1apXXc+zYMbvvvvts8ODBlpKSYrfddpsdOnQo4n7ee+89mz59uiUnJ1tGRoYtWrTIurq6LvA0n2/27Nk2cuRIS0pKsmHDhtnUqVO9cGIWO3N+1mcDSqzMOWvWLBs+fLglJSXZxRdfbLNmzYr42SCxMqeZ2fr16238+PHm8/ls7Nix9oc//CFiPRaei8zMXnrpJZN00t7NYud8hsNhmz9/vuXm5trAgQPt0ksvtYceeijiUuhoO59xZp/6MXMAAAAOiKrPoAAAgC8HAgoAAHAOAQUAADiHgAIAAJxDQAEAAM4hoAAAAOcQUAAAgHMIKAAAwDkEFAAA4BwCCgAAcA4BBQAAOOf/AGN4XjKZm9UmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = plt.imread('./traindata/0.jpg')   # reading image using its name\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da41986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image_ID  Class\n",
       "0    0.jpg      1\n",
       "1    1.jpg      1\n",
       "2    2.jpg      1\n",
       "3    3.jpg      1\n",
       "4    4.jpg      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('mapping.csv')     # reading the csv file\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39a7f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ ]     # creating an empty array\n",
    "tpath=\"traindata/\"\n",
    "for img_name in data.Image_ID:\n",
    "    img = plt.imread(tpath + img_name)\n",
    "    X.append(img)  # storing each image in array X\n",
    "X = np.array(X)    # converting list to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8119c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.Class\n",
    "dummy_y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f7cf107",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "for i in range(0,X.shape[0]):\n",
    "    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)      # reshaping to 224*224*3\n",
    "    image.append(a)\n",
    "X = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2555ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "X = preprocess_input(X,data_format=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21006e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af20a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d94402",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb02ec43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 11s 2s/step\n",
      "3/3 [==============================] - 4s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((155, 7, 7, 512), (67, 7, 7, 512))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "555111d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(155, 7*7*512)      # converting to 1-D\n",
    "X_valid = X_valid.reshape(67, 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a5a6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train/X_train.max()      # centering the data\n",
    "X_valid = X_valid/X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57001716",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))    # input layer\n",
    "model.add(Dense(units=1024, activation='sigmoid')) # hidden layer\n",
    "model.add(Dense(2, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "586cff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1024)              25691136  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,693,186\n",
      "Trainable params: 25,693,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e36420f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20e00a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 337ms/step - loss: 0.8745 - accuracy: 0.5032 - val_loss: 1.0042 - val_accuracy: 0.5522\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.5033 - accuracy: 0.7419 - val_loss: 0.7901 - val_accuracy: 0.6866\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.2932 - accuracy: 0.8645 - val_loss: 0.8394 - val_accuracy: 0.7463\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.1656 - accuracy: 0.9290 - val_loss: 0.8557 - val_accuracy: 0.6866\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.1333 - accuracy: 0.9613 - val_loss: 0.7819 - val_accuracy: 0.7612\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 1s 259ms/step - loss: 0.0686 - accuracy: 0.9935 - val_loss: 0.7926 - val_accuracy: 0.7910\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.0659 - accuracy: 0.9935 - val_loss: 0.7656 - val_accuracy: 0.7612\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 1s 261ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.7888 - val_accuracy: 0.7761\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.7929 - val_accuracy: 0.7463\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.7674 - val_accuracy: 0.7612\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.7644 - val_accuracy: 0.7761\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.7619 - val_accuracy: 0.7761\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.7688 - val_accuracy: 0.7910\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.7706 - val_accuracy: 0.7910\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.7796 - val_accuracy: 0.7910\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 1s 266ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.7821 - val_accuracy: 0.7910\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 1s 262ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.7895 - val_accuracy: 0.7761\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 1s 265ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.7921 - val_accuracy: 0.7761\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.7930 - val_accuracy: 0.7761\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 1s 258ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.7927 - val_accuracy: 0.7761\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 1s 262ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.7955 - val_accuracy: 0.7910\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.8060\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 1s 264ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.8013 - val_accuracy: 0.7761\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 1s 269ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.8047 - val_accuracy: 0.7761\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 1s 264ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.8068 - val_accuracy: 0.7761\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.8089 - val_accuracy: 0.7761\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8120 - val_accuracy: 0.7910\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.8132 - val_accuracy: 0.7910\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.8154 - val_accuracy: 0.7910\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.7910\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8196 - val_accuracy: 0.7910\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.8207 - val_accuracy: 0.7910\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8219 - val_accuracy: 0.8060\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8241 - val_accuracy: 0.8060\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8279 - val_accuracy: 0.8060\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8298 - val_accuracy: 0.8060\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8318 - val_accuracy: 0.7910\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8341 - val_accuracy: 0.7910\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8341 - val_accuracy: 0.8209\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8364 - val_accuracy: 0.8209\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8387 - val_accuracy: 0.8209\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8412 - val_accuracy: 0.8209\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8437 - val_accuracy: 0.8209\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8454 - val_accuracy: 0.7910\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8461 - val_accuracy: 0.7910\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8477 - val_accuracy: 0.8209\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8503 - val_accuracy: 0.8209\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8510 - val_accuracy: 0.8209\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8526 - val_accuracy: 0.8209\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8534 - val_accuracy: 0.8209\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8551 - val_accuracy: 0.8209\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8572 - val_accuracy: 0.8209\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8590 - val_accuracy: 0.8209\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8607 - val_accuracy: 0.8209\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8629 - val_accuracy: 0.8209\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8638 - val_accuracy: 0.8209\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8649 - val_accuracy: 0.8209\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8662 - val_accuracy: 0.8209\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8687 - val_accuracy: 0.8209\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8701 - val_accuracy: 0.8209\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8719 - val_accuracy: 0.8209\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8734 - val_accuracy: 0.8209\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8748 - val_accuracy: 0.8209\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8748 - val_accuracy: 0.8209\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8770 - val_accuracy: 0.8209\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8792 - val_accuracy: 0.8209\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8808 - val_accuracy: 0.8209\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8818 - val_accuracy: 0.8209\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8826 - val_accuracy: 0.8209\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8843 - val_accuracy: 0.8209\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8858 - val_accuracy: 0.8209\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8871 - val_accuracy: 0.8209\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8882 - val_accuracy: 0.8209\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8891 - val_accuracy: 0.8209\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8900 - val_accuracy: 0.8209\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8914 - val_accuracy: 0.8209\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8927 - val_accuracy: 0.8209\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8942 - val_accuracy: 0.8209\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8960 - val_accuracy: 0.8209\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8970 - val_accuracy: 0.8209\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8991 - val_accuracy: 0.8209\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9008 - val_accuracy: 0.8209\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9023 - val_accuracy: 0.8209\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9037 - val_accuracy: 0.8209\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9044 - val_accuracy: 0.8209\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9054 - val_accuracy: 0.8209\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9065 - val_accuracy: 0.8209\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9072 - val_accuracy: 0.8209\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9086 - val_accuracy: 0.8209\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9100 - val_accuracy: 0.8209\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9115 - val_accuracy: 0.8209\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 9.8069e-04 - accuracy: 1.0000 - val_loss: 0.9123 - val_accuracy: 0.8209\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 1s 234ms/step - loss: 9.6261e-04 - accuracy: 1.0000 - val_loss: 0.9132 - val_accuracy: 0.8209\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 9.4653e-04 - accuracy: 1.0000 - val_loss: 0.9143 - val_accuracy: 0.8209\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 9.3214e-04 - accuracy: 1.0000 - val_loss: 0.9151 - val_accuracy: 0.8209\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 9.1118e-04 - accuracy: 1.0000 - val_loss: 0.9161 - val_accuracy: 0.8209\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 8.9642e-04 - accuracy: 1.0000 - val_loss: 0.9181 - val_accuracy: 0.8209\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 8.8054e-04 - accuracy: 1.0000 - val_loss: 0.9195 - val_accuracy: 0.8209\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 8.6461e-04 - accuracy: 1.0000 - val_loss: 0.9200 - val_accuracy: 0.8209\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 8.5100e-04 - accuracy: 1.0000 - val_loss: 0.9211 - val_accuracy: 0.8209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f541607940>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "494768fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e7f766b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_model.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "joblib.dump(model, 'trained_model.pkl')\n",
    "#saving model to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd78c95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "import joblib\n",
    "model = joblib.load('trained_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8d52fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"Accident-2.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    path=\"test/\"\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =path+\"test%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cf0f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9047ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for img_name in test.Image_ID:\n",
    "    img = plt.imread(path + img_name)\n",
    "    test_image.append(img)\n",
    "test_img = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f32558f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for i in range(0,test_img.shape[0]):\n",
    "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
    "    test_image.append(a)\n",
    "test_image = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff1260b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 401ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, 7, 7, 512)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing the images\n",
    "test_image = preprocess_input(test_image, data_format=None)\n",
    "\n",
    "# extracting features from the images using pretrained model\n",
    "test_image = base_model.predict(test_image)\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9f69282",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = test_image.reshape(9, 7*7*512)\n",
    "\n",
    "# zero centered images\n",
    "test_image = test_image/test_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "721c02ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb5b165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02723292 0.97276706]\n",
      " [0.0166962  0.9833038 ]\n",
      " [0.00550224 0.9944977 ]\n",
      " [0.0142737  0.98572636]\n",
      " [0.07931869 0.9206813 ]\n",
      " [0.10126945 0.8987305 ]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f040ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,9):\n",
    "    if predictions[i][0]<predictions[i][1]:\n",
    "        print(\"No Accident\")\n",
    "    else:\n",
    "        print(\"Accident\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e66b91f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoLoc = Nominatim(user_agent=\"GetLoc\")\n",
    "g = geocoder.ip('me')\n",
    "locname = geoLoc.reverse(g.latlng)\n",
    "account_sid = \"ACc2a09b28a2a55c31129cb963048c4024\"\n",
    "auth_token = \"72fa1731b0e3d58c8eab79830e178c49\"\n",
    "client = Client(account_sid, auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80b3e4f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\thepywizard\\Documents\\dothack23\\accidentweb3\\ml\\acc-det.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thepywizard/Documents/dothack23/accidentweb3/ml/acc-det.ipynb#X46sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ret,frame\u001b[39m=\u001b[39mcap\u001b[39m.\u001b[39mread()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thepywizard/Documents/dothack23/accidentweb3/ml/acc-det.ipynb#X46sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mif\u001b[39;00m ret\u001b[39m==\u001b[39m\u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/thepywizard/Documents/dothack23/accidentweb3/ml/acc-det.ipynb#X46sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mif\u001b[39;00m predictions[\u001b[39mint\u001b[39;49m(i\u001b[39m/\u001b[39;49m\u001b[39m15\u001b[39;49m)\u001b[39m%\u001b[39;49m\u001b[39m9\u001b[39;49m][\u001b[39m0\u001b[39m]\u001b[39m<\u001b[39mpredictions[\u001b[39mint\u001b[39m(i\u001b[39m/\u001b[39m\u001b[39m15\u001b[39m)\u001b[39m%\u001b[39m\u001b[39m9\u001b[39m][\u001b[39m1\u001b[39m]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thepywizard/Documents/dothack23/accidentweb3/ml/acc-det.ipynb#X46sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         percent \u001b[39m=\u001b[39m predictions[\u001b[39mint\u001b[39m(i\u001b[39m/\u001b[39m\u001b[39m15\u001b[39m)\u001b[39m%\u001b[39m\u001b[39m9\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thepywizard/Documents/dothack23/accidentweb3/ml/acc-det.ipynb#X46sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         predict\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo Accident\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m#+ str(percent)\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 6 is out of bounds for axis 0 with size 6"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('Accident-2.mp4')\n",
    "i=0\n",
    "flag=0\n",
    "snapshot_counter = 0\n",
    "imgflag=0\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    if ret==True:\n",
    "        if predictions[int(i/15)%9][0]<predictions[int(i/15)%9][1]:\n",
    "            percent = predictions[int(i/15)%9][1]*100\n",
    "            predict=\"No Accident\" #+ str(percent)\n",
    "        else:\n",
    "            percent = predictions[int(i/15)%9][0]*100\n",
    "            predict=\"Accident \" + str(percent)\n",
    "            flag=1\n",
    "\n",
    "            if imgflag==0 and percent >80:\n",
    "                AccSnapshotDir = 'AccSnaps/'      \n",
    "                snapshot_filename = f'accident_snapshot_{snapshot_counter}.jpg'\n",
    "                cv2.imwrite(AccSnapshotDir + snapshot_filename, frame)\n",
    "                snapshot_counter += 1\n",
    "                imgflag=1\n",
    "\n",
    "        # Save a snapshot at the time of accident\n",
    "            \n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                predict,\n",
    "                (50, 50),\n",
    "                font, 1,\n",
    "                (0, 255, 255),\n",
    "                3,\n",
    "                cv2.LINE_4)\n",
    "        # cv2.putText(frame,\n",
    "        #         percent,\n",
    "        #         (0, 255, 255),\n",
    "        #         font, 1,\n",
    "        #         (0, 255, 255),\n",
    "        #         3,\n",
    "        #         cv2.LINE_4)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        i=i+1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "# if flag==1:\n",
    "#     client.messages.create(\n",
    "#                  body=\"Accident detected in \"+locname.address,\n",
    "#                  from_= \"+12568040182\",\n",
    "#                  to= \"+919074062399\"\n",
    "#                  )\n",
    "\n",
    "# release the cap object\n",
    "cap.release()\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a76e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a6a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aaa0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab12e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38071c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
